# RegularizaciÃ³n en RegresiÃ³n Lineal ğŸŒŸ

Â¡Hola y bienvenidos a la cuarta clase! Hoy vamos a explorar la **RegularizaciÃ³n**, una tÃ©cnica clave para mejorar nuestros modelos de regresiÃ³n lineal y evitar problemas como el sobreajuste. ğŸš€

## Â¿QuÃ© es la RegularizaciÃ³n? ğŸ¤”

En la regresiÃ³n lineal, **regularizaciÃ³n** es una tÃ©cnica que ayuda a simplificar el modelo para que no se ajuste demasiado a los datos de entrenamiento. Esto se conoce como **sobreajuste** (overfitting). Un modelo sobreajustado funciona muy bien con los datos de entrenamiento pero falla con datos nuevos.

## Â¿CÃ³mo Funciona la RegularizaciÃ³n? ğŸ”§

La regularizaciÃ³n aÃ±ade un **tÃ©rmino de penalizaciÃ³n** a la funciÃ³n de costo del modelo. Este tÃ©rmino penaliza los coeficientes del modelo si son demasiado grandes, lo que ayuda a evitar que el modelo se vuelva demasiado complejo.

### Tipos de RegularizaciÃ³n

#### 1. **RegularizaciÃ³n Lasso (L1)** ğŸ§©

**Lasso** (Least Absolute Shrinkage and Selection Operator) aÃ±ade una penalizaciÃ³n proporcional a la **suma de los valores absolutos** de los coeficientes del modelo. Esto puede llevar a que algunos coeficientes se reduzcan a cero, eliminando efectivamente algunas variables del modelo.




#### 2. **RegularizaciÃ³n Ridge (L2)** ğŸŒ

**Ridge** aÃ±ade una penalizaciÃ³n proporcional a la **suma de los cuadrados** de los coeficientes del modelo. Esto hace que los coeficientes se reduzcan, pero rara vez a cero, ayudando a manejar problemas de multicolinealidad.



## Ejemplo PrÃ¡ctico en CÃ³digo ğŸ–¥ï¸

Vamos a ver cÃ³mo aplicar Lasso y Ridge en Python usando `scikit-learn`. Suponemos que ya tenemos un dataset y queremos ajustar un modelo con regularizaciÃ³n.

```python
# Importar librerÃ­as necesarias
from sklearn.linear_model import Lasso, Ridge
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# Crear un dataset de ejemplo
X, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Ajustar modelo Lasso
lasso = Lasso(alpha=0.1)  # alpha es el parÃ¡metro de regularizaciÃ³n
lasso.fit(X_train, y_train)

# Ajustar modelo Ridge
ridge = Ridge(alpha=0.1)  # alpha es el parÃ¡metro de regularizaciÃ³n
ridge.fit(X_train, y_train)

# Hacer predicciones y evaluar
print(f"Coeficientes Lasso: {lasso.coef_}")
print(f"Coeficientes Ridge: {ridge.coef_}")
